# -*- coding: utf-8 -*-
"""Goeduhub_Assignment17.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18-yEPn--N7u2nAoRQr1UUoXWryLTk2fj
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sb
# %matplotlib inline
import sklearn
# /content/drive/MyDrive/Goeduhub/
movie = pd.read_csv("movie_metadata.csv")
movie.head()

movie.shape

movie.columns

movie.info()

movie.corr()

plt.figure(figsize = (10, 10))
sb.heatmap(movie.corr())

movie.describe()

movie.isnull().sum()

movie["color"].unique()

movie["color"] = movie["color"].replace(np.NaN, " Black and White")
movie["color"].unique()

sb.countplot(data = movie, x = "color")

movie["num_critic_for_reviews"] = movie["num_critic_for_reviews"].replace(np.NaN, movie["num_critic_for_reviews"].mean())
movie["num_critic_for_reviews"].isnull().sum()

movie["num_critic_for_reviews"].plot(kind = "hist", bins = 20)

movie["duration"].isnull().sum()

movie["duration"] = movie["duration"].replace(np.NaN, movie["duration"].mean())
movie["duration"].isnull().sum()

movie["duration"].plot(kind = "hist", bins = 20)

movie["director_facebook_likes"].nunique()

movie["director_facebook_likes"].isnull().sum()

movie["director_facebook_likes"] = movie["director_facebook_likes"].replace(np.NaN, movie["director_facebook_likes"].mean())
movie["director_facebook_likes"].isnull().sum()

movie["director_facebook_likes"].plot(kind = "hist", bins = 20)

movie["actor_3_facebook_likes"] = movie["actor_3_facebook_likes"].replace(np.NaN, movie["actor_3_facebook_likes"].mean())
movie["actor_3_facebook_likes"].isnull().sum()

movie["actor_3_facebook_likes"].plot(kind = "hist")

movie["actor_1_facebook_likes"] = movie["actor_1_facebook_likes"].replace(np.NaN, movie["actor_1_facebook_likes"].mean())
movie["actor_1_facebook_likes"].isnull().sum()

movie["actor_1_facebook_likes"].plot(kind = "hist")

movie["genres"].value_counts()[:10].plot(kind = "bar")

movie["gross"] = movie["gross"].replace(np.NaN, movie["gross"].mean())
movie["gross"].isnull().sum()

movie["language"].unique()

movie["language"].value_counts()

movie["language"].value_counts()[:10].plot(kind = "bar")

movie["country"].value_counts()[:10].plot(kind = "bar")

movie["imdb_score"].plot(kind = "hist")

movie["title_year"].value_counts().head(10).plot(kind = "bar")

features = movie[["director_name", "genres", "movie_title", "actor_1_name", "actor_2_name", "actor_3_name"]]
features.head()

features["genres"] = features["genres"].apply(lambda x: str(x).replace("|", " "))
features.head()

features["movie_title"][0]

features["movie_title"] = features["movie_title"].apply(lambda a: a[:-1])
features["movie_title"]

features["director_genre_actors"] = features["director_name"] + " " + features["genres"] + " " + features["actor_1_name"] + " " + features["actor_2_name"] + " " + features["actor_3_name"]
features.head()

features = features.drop(["director_name", "actor_1_name", "actor_2_name", "actor_3_name", "genres"], axis = 1)
features.head()

features.isnull().sum()

features.fillna(" ", inplace = True)
features.head()

features.isnull().sum()

from sklearn.feature_extraction.text import CountVectorizer

vector = CountVectorizer()
vector_matrix = vector.fit_transform(features["director_genre_actors"])
print(vector_matrix)

from sklearn.neighbors import NearestNeighbors
model_knn = NearestNeighbors(metric = "cosine", n_neighbors = 20, radius = 1)
model_knn.fit(vector_matrix)

from sklearn.metrics.pairwise import cosine_similarity

similarity_matrix = cosine_similarity(vector_matrix)
print(similarity_matrix)

def recommendation(movie_name):
  if movie_name not in features["movie_title"].unique():
    print("This movie is not in our dataset, either you have made spelling mistake or you have to try with different movie!")
  else:
    i = features.loc[features["movie_title"] == movie_name].index[0] 
    list_movie = list(enumerate(similarity_matrix[i]))
    list_movie = sorted(list_movie, key = lambda x: x[1], reverse = True)
    list_movie = list_movie[1:6]
    lst = []
    for i in range(len(list_movie)):
      j = list_movie[i][0]
      lst.append(features["movie_title"][j])
    
    recommended = dict({"Recommended Movies": lst})   
    # recommended.drop_duplicates
    return recommended

recommendation("Avatar")

recommendation("Pirates of the Caribbean: At World's End")

import pickle
pickle.dump(model_knn, open("recomm.pkl", "wb"))

if __name__ == "__main__":
  recommendation